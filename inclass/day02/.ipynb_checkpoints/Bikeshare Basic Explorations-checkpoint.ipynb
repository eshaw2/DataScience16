{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Exploration of the Bike Share Kaggle Dataset\n",
    "\n",
    "In this document, I will show you how to do some basic exploration and cleaning of the kaggle Bike share dataset.  The data is checked into the repository under `DataScience16/datasets/kaggle_bikeshare_train.csv`.  The code here relies on you running this notebook from the `DataScience16/exercises` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will read the data into a Pandas dataframe.  The NSFG class from ThinkStats reading is really just a thin wrapper around `pandas.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              datetime  season  holiday  workingday  weather  temp   atemp  \\\n",
      "0  2011-01-01 00:00:00       1        0           0        1  9.84  14.395   \n",
      "1  2011-01-01 01:00:00       1        0           0        1  9.02  13.635   \n",
      "2  2011-01-01 02:00:00       1        0           0        1  9.02  13.635   \n",
      "3  2011-01-01 03:00:00       1        0           0        1  9.84  14.395   \n",
      "4  2011-01-01 04:00:00       1        0           0        1  9.84  14.395   \n",
      "\n",
      "   humidity  windspeed  casual  registered  count  \n",
      "0        81          0       3          13     16  \n",
      "1        80          0       8          32     40  \n",
      "2        80          0       5          27     32  \n",
      "3        75          0       3          10     13  \n",
      "4        75          0       0           1      1  \n",
      "             season       holiday    workingday       weather         temp  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.00000   \n",
      "mean       2.506614      0.028569      0.680875      1.418427     20.23086   \n",
      "std        1.116174      0.166599      0.466159      0.633839      7.79159   \n",
      "min        1.000000      0.000000      0.000000      1.000000      0.82000   \n",
      "25%        2.000000      0.000000      0.000000      1.000000     13.94000   \n",
      "50%        3.000000      0.000000      1.000000      1.000000     20.50000   \n",
      "75%        4.000000      0.000000      1.000000      2.000000     26.24000   \n",
      "max        4.000000      1.000000      1.000000      4.000000     41.00000   \n",
      "\n",
      "              atemp      humidity     windspeed        casual    registered  \\\n",
      "count  10886.000000  10886.000000  10886.000000  10886.000000  10886.000000   \n",
      "mean      23.655084     61.886460     12.799395     36.021955    155.552177   \n",
      "std        8.474601     19.245033      8.164537     49.960477    151.039033   \n",
      "min        0.760000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%       16.665000     47.000000      7.001500      4.000000     36.000000   \n",
      "50%       24.240000     62.000000     12.998000     17.000000    118.000000   \n",
      "75%       31.060000     77.000000     16.997900     49.000000    222.000000   \n",
      "max       45.455000    100.000000     56.996900    367.000000    886.000000   \n",
      "\n",
      "              count  \n",
      "count  10886.000000  \n",
      "mean     191.574132  \n",
      "std      181.144454  \n",
      "min        1.000000  \n",
      "25%       42.000000  \n",
      "50%      145.000000  \n",
      "75%      284.000000  \n",
      "max      977.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../../datasets/kaggle_bikeshare_train.csv')\n",
    "\n",
    "print data.head()\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Missing values\n",
    "\n",
    "When you first work with a dataset, it's always a good idea to check for missing values.  To do this we will use the pandas isnull() function.  Keep in mind that this is just one method of determining whether or not data is missing.  It will only tell part of the story.  What are some other ways of figuring out if there are missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime      0\n",
       "season        0\n",
       "holiday       0\n",
       "workingday    0\n",
       "weather       0\n",
       "temp          0\n",
       "atemp         0\n",
       "humidity      0\n",
       "windspeed     0\n",
       "casual        0\n",
       "registered    0\n",
       "count         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating our Recodes\n",
    "\n",
    "The next thing to do is to make sure we understand some of recodes in the data.  We know that we are trying to predict count which is presumably a combination of casual and registered.  Let's check this hypothesis.  Note: this is more about checking our own understanding rather than checking to validity of the data (since we can be reasonably confident that it is correct).  However, you could imagine this would be a good unit test for recodes that you created yourself.  In fact, this unit test would serve as a guide for anyone else reading your code as to what exactly the recode means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed we used the dictionary notation to lookup `count` whereas we used the dot-notation to lookup registered and casual.  The reason for this is that is a method of the DataFrame class, and thus it is ambiguous which we are referring to (the column or the method).  Let's learn more about this by printing out the type of `data.registered`, `data['registered']`, `data['count']`, and `data.count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Basic Properties of the Data\n",
    "\n",
    "Next, we will look at each of the variables in some more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 500\n",
    "print data.casual.value_counts().sort_index()\n",
    "print data.registered.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty hard to get much out of.  Let's see if we can do better by merging the two series together into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([data.casual.value_counts(), data.registered.value_counts()], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's much more revealing!  What sorts of patterns does that reveal?  How does the behavior of the two user populations differ?\n",
    "\n",
    "They say a picture is worth a thousand words (or a thousand numbers).  Let's create a visual representation of the counts above.  This is called a histogram.  We will do this using Seaborn, but you will have a chance to learn how to do it using ThinkStats and ThinkPlot in the reading for next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Relationship Between Ridership and Other Factors\n",
    "\n",
    "We will investigate some different methods for determining how the value of one factor affects the value of another.  As a first example, let's determine the effect of whether or not it is a working day has on the ridership for both casual and registered riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll use the `groupby` operation to do this in an even more convenient fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Another cool use of `groupby` is that you can specify multiple columns to essentially get conjunctions.  Let's test the interaction between the `season` column and the `holiday` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recodes\n",
    "\n",
    "Next, we will parse through the datetime field to create some recodes that will allow us to access various fields datetime.  A typical entry in the datetime columns looks like this: `2011-04-05 13:00:00`.  Next, we will create a function that converts this string into a tuple of integers in the format year, month, day, hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will apply our function to create some new columns in our data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, we will use our recodes to create some time series plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go Play!\n",
    "\n",
    "Explore some interesting facets of the data.  Think carefully about whether the results are best communicated in tabular format, raw text, or graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
